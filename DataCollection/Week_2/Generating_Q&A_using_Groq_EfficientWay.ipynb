{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5df673-35ab-4984-abb6-974b34aa4026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q PyPDF2\n",
    "!pip install -q tiktoken   # BPE\n",
    "!pip install -q groq\n",
    "!pip install -q -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb410c2-d6c6-4894-bd44-cb786f13deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import tiktoken\n",
    "import os\n",
    "from groq import Groq\n",
    "import groq\n",
    "import glob\n",
    "import time\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f736516c-96ea-4d45-b8a2-43144310ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Text From pages\n",
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    for page in reader.pages:\n",
    "        yield page.extract_text()\n",
    "\n",
    "# Counting the number of tokens\n",
    "def number_of_tokens(text):\n",
    "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "  ids = tokenizer.encode(text)\n",
    "  return len(ids)\n",
    "\n",
    "# Function to summarize text\n",
    "def summarize_text(text, chunk_size=500,device=0):\n",
    "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\",device=device)\n",
    "\n",
    "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        max_length = min(150,max(20,number_of_tokens(chunk) // 2))\n",
    "        min_length = min(50,max(10,number_of_tokens(chunk) // 2))\n",
    "        summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']\n",
    "        summaries.append(summary)\n",
    "\n",
    "    combined_summary = \" \".join(summaries)\n",
    "    return combined_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0221002-5287-44d3-a731-8fdd148fbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['GROQ_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c18eb50-833c-4307-8a2c-7876656ff9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Groq client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c0b8c8-1b15-4046-a1ab-1f11c837fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate Q&A pairs from text using Groq's API\n",
    "def generate_questions_and_answers(text,text_summarization, model=\"llama-3.1-70b-versatile\"):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Generate questions and answers from the given text. \n",
    "                The answers should be based on what's in the text, not on your knowledge. \n",
    "                Follow this model in generating: 'Q: ...\\nA: ...'. \n",
    "                Here is the text: {text}. \n",
    "                Also, consider the summarization of the previous text to help \n",
    "                in generating questions and answers: {text_summarization}.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    # Extracting the content of the response\n",
    "    if response and response.choices:\n",
    "        return response.choices[0].message.content\n",
    "    else:\n",
    "        return \"No Q&A generated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0596d56b-c665-416b-b395-6c21bc657c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = glob.glob('Book_?.pdf')\n",
    "\n",
    "def Generate():\n",
    "    Number_of_Tokens_per_minute = 0\n",
    "    Number_of_Request_per_minute = 0\n",
    "    Number_of_Tokens_per_day = 0\n",
    "    Number_of_Request_per_day = 0\n",
    "    for i,pdf in enumerate(pdf_files):\n",
    "        output_file = f'Book_{i+1}_q&a.txt'\n",
    "        text_summarization = \"\"\n",
    "        print(f\"Book {i+1}\")\n",
    "        with open(output_file, 'w', encoding='utf-8') as file:\n",
    "            for j,page_text in enumerate(read_pdf(pdf)):\n",
    "\n",
    "                current_page_tokens = number_of_tokens(page_text)\n",
    "                current_summary_tokens = number_of_tokens(text_summarization)\n",
    "                \n",
    "                Number_of_Tokens_per_minute += (current_page_tokens + current_summary_tokens)\n",
    "                Number_of_Tokens_per_day += (current_page_tokens + current_summary_tokens)\n",
    "                \n",
    "                if(Number_of_Tokens_per_minute > 130000 or Number_of_Request_per_minute >= 100):\n",
    "                    Number_of_Tokens_per_minute = 0\n",
    "                    Number_of_Request_per_minute = 0\n",
    "                    print(\"please just wait 1 min ....\")\n",
    "                    time.sleep(65)\n",
    "                    \n",
    "                if(Number_of_Tokens_per_day >= 1000000 or Number_of_Request_per_day >= 14400):\n",
    "                    Number_of_Tokens_per_day = 0\n",
    "                    Number_of_Request_per_day = 0\n",
    "                    Number_of_Tokens_per_minute = 0\n",
    "                    Number_of_Request_per_minute = 0\n",
    "                    print(\"please you have to wait 1 day ....\")\n",
    "                    time.sleep(86100)\n",
    "                    \n",
    "                q_and_a = generate_questions_and_answers(page_text,text_summarization)\n",
    "                current_q_and_a_tokens = number_of_tokens(q_and_a)\n",
    "\n",
    "                Number_of_Tokens_per_minute += current_q_and_a_tokens\n",
    "                Number_of_Tokens_per_day += current_q_and_a_tokens\n",
    "                \n",
    "                Number_of_Request_per_minute += 1\n",
    "                Number_of_Request_per_day += 1\n",
    "                text_summarization += summarize_text(page_text)\n",
    "                \n",
    "                file.write(f\"Page {j+1} Q&A:\\n{q_and_a}\\n\\n\")\n",
    "                if((j+1)%10==0 or j==0):\n",
    "                    print(f\"-> Page {j+1} converted\\n-> ...\")\n",
    "            \n",
    "            print(f\"-> Q&A generation for pdf {i+1} completed.\")\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4dc0a-8053-407e-99f1-23c71df3fbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 1\n",
      "-> Page 1 converted\n",
      "-> ...\n",
      "-> Page 10 converted\n",
      "-> ...\n",
      "-> Page 20 converted\n",
      "-> ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but your input_length is only 4. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please just wait 1 min ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but your input_length is only 13. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n",
      "Your max_length is set to 20, but your input_length is only 4. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Q&A generation for pdf 1 completed.\n",
      "\n",
      "\n",
      "Book 2\n",
      "-> Page 1 converted\n",
      "-> ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but your input_length is only 17. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Page 10 converted\n",
      "-> ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Page 20 converted\n",
      "-> ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but your input_length is only 13. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n",
      "Your max_length is set to 20, but your input_length is only 15. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n",
      "Your max_length is set to 20, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Page 30 converted\n",
      "-> ...\n"
     ]
    }
   ],
   "source": [
    "Generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487afa76-5fbc-40eb-b8ef-b50399d47ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763c910-7110-40b0-8010-52c705380565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb02b1c-ec70-49e1-9dd8-f8c658094f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
